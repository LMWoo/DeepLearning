{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bd084a8",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a07bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import numpy as np\n",
    "from npRnn import npRnn\n",
    "import cpp as cpp\n",
    "\n",
    "seq_length = 28\n",
    "input_size = 28\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "num_classes = 10\n",
    "batch_size = 1\n",
    "num_epochs = 1\n",
    "learning_rate = 0.01\n",
    "start_time = 0\n",
    "\n",
    "data_path = \"../../data/mnist\"\n",
    "train_dataset = torchvision.datasets.MNIST(root=data_path, train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root=data_path, train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d66ed8e",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ab96dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(c1, c2, w=1, h=1, fc=False):\n",
    "    fan_1 = c2 * w * h\n",
    "    fan_2 = c1 * w * h\n",
    "    ratio = np.sqrt(6.0 / (fan_1 + fan_2))\n",
    "    params = ratio * (2 * np.random.random((c1, c2, w, h)) - 1)\n",
    "    if fc:\n",
    "        params = params.reshape(c1, c2)\n",
    "    return params\n",
    "    \n",
    "np_U = xavier_init(hidden_size, input_size, fc=True)\n",
    "np_W = xavier_init(hidden_size, hidden_size, fc=True)\n",
    "np_V = xavier_init(hidden_size, hidden_size, fc=True)\n",
    "np_FC_W = xavier_init(num_classes, hidden_size, fc=True)\n",
    "U = cpp.cppTensor(np_U.reshape(hidden_size, input_size))\n",
    "W = cpp.cppTensor(np_W.reshape(hidden_size, hidden_size))\n",
    "V = cpp.cppTensor(np_V.reshape(hidden_size, hidden_size))\n",
    "FC_W = cpp.cppTensor(np_FC_W)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "interval = 5000\n",
    "\n",
    "np_iter_loss = 0\n",
    "cpu_iter_loss = 0\n",
    "gpu_iter_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66595e",
   "metadata": {},
   "source": [
    "# Numpy Rnn Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27fc9391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train numpy hidden_size 128\n",
      "numpy epoch 1/1 iter 5000/60000 loss 1.5735\n",
      "elased time 12.266170740127563\n",
      "numpy epoch 1/1 iter 10000/60000 loss 1.1819\n",
      "elased time 13.246779441833496\n",
      "numpy epoch 1/1 iter 15000/60000 loss 0.9659\n",
      "elased time 13.423335552215576\n",
      "numpy epoch 1/1 iter 20000/60000 loss 0.7735\n",
      "elased time 13.36319351196289\n",
      "numpy epoch 1/1 iter 25000/60000 loss 0.7409\n",
      "elased time 13.136044263839722\n",
      "numpy epoch 1/1 iter 30000/60000 loss 0.6307\n",
      "elased time 13.6442551612854\n",
      "numpy epoch 1/1 iter 35000/60000 loss 0.6360\n",
      "elased time 13.36297082901001\n",
      "numpy epoch 1/1 iter 40000/60000 loss 0.5868\n",
      "elased time 13.253770112991333\n",
      "numpy epoch 1/1 iter 45000/60000 loss 0.6033\n",
      "elased time 13.687143087387085\n",
      "numpy epoch 1/1 iter 50000/60000 loss 0.5741\n",
      "elased time 13.667681694030762\n",
      "numpy epoch 1/1 iter 55000/60000 loss 0.5442\n",
      "elased time 13.810617685317993\n",
      "numpy epoch 1/1 iter 60000/60000 loss 0.5481\n",
      "elased time 13.560202598571777\n"
     ]
    }
   ],
   "source": [
    "print(\"start train numpy hidden_size {}\".format(hidden_size))\n",
    "\n",
    "np_model = npRnn(learning_rate, seq_length, hidden_size, num_classes, np_U, np_W, np_V, np_FC_W)\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (train_images, train_labels) in enumerate(train_loader):\n",
    "        np_images = train_images.reshape(seq_length, batch_size, input_size).detach().numpy()\n",
    "        np_labels = train_labels.detach().numpy()\n",
    "        np_hprev = np.zeros((hidden_size, 1))\n",
    "\n",
    "        np_outputs = np_model.forward(np_images, np_hprev)\n",
    "        np_Y, np_loss = np_model.cross_entropy_loss(np_outputs, np_labels)\n",
    "        np_dY = np_model.deriv_softmax(np_Y, np_labels)\n",
    "        np_gradients = np_model.backward(np_dY)\n",
    "        np_model.optimizer_step(np_gradients)\n",
    "        np_iter_loss += np.sum(np_loss)\n",
    "\n",
    "        if (i + 1) % interval == 0:\n",
    "            print(\"numpy epoch {}/{} iter {}/{} loss {:.4f}\".format(epoch + 1, num_epochs, i + 1, total_step, np_iter_loss / interval))\n",
    "            print(\"elased time {}\".format(time.time() - start_time))\n",
    "            start_time = time.time()\n",
    "            np_iter_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dedfb6",
   "metadata": {},
   "source": [
    "# CPU Rnn Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cddda8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train numpy hidden_size 128\n",
      "cpu epoch 1/1 iter 5000/60000 loss 1.5981\n",
      "elased time 23.97615647315979\n",
      "cpu epoch 1/1 iter 10000/60000 loss 0.9997\n",
      "elased time 23.99291706085205\n",
      "cpu epoch 1/1 iter 15000/60000 loss 0.7095\n",
      "elased time 24.202476978302002\n",
      "cpu epoch 1/1 iter 20000/60000 loss 0.6657\n",
      "elased time 24.817394256591797\n",
      "cpu epoch 1/1 iter 25000/60000 loss 0.6062\n",
      "elased time 24.52069640159607\n",
      "cpu epoch 1/1 iter 30000/60000 loss 0.5609\n",
      "elased time 23.417757511138916\n",
      "cpu epoch 1/1 iter 35000/60000 loss 0.5040\n",
      "elased time 23.6754629611969\n",
      "cpu epoch 1/1 iter 40000/60000 loss 0.5008\n",
      "elased time 23.760572910308838\n",
      "cpu epoch 1/1 iter 45000/60000 loss 0.5100\n",
      "elased time 23.97665572166443\n",
      "cpu epoch 1/1 iter 50000/60000 loss 0.4457\n",
      "elased time 24.099708557128906\n",
      "cpu epoch 1/1 iter 55000/60000 loss 0.4729\n",
      "elased time 23.84420609474182\n",
      "cpu epoch 1/1 iter 60000/60000 loss 0.4747\n",
      "elased time 23.813793182373047\n"
     ]
    }
   ],
   "source": [
    "print(\"start train numpy hidden_size {}\".format(hidden_size))\n",
    "\n",
    "cpu_model = cpp.cppRnn(learning_rate, U, W, V, FC_W, seq_length, input_size, hidden_size, num_classes)\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (train_images, train_labels) in enumerate(train_loader):\n",
    "        train_images = train_images.reshape(seq_length, batch_size, input_size).detach().numpy()\n",
    "        train_labels = train_labels.detach().numpy()\n",
    "        train_hprev = np.zeros((hidden_size, 1))\n",
    "\n",
    "        cpu_images = [cpp.cppTensor(train_images[j]) for j in range(len(train_images))]\n",
    "        cpu_hprev = cpp.cppTensor(train_hprev)\n",
    "        cpu_labels = cpp.cppTensor(train_labels)\n",
    "\n",
    "        cpu_outputs = cpp.cppTensor(np.zeros((num_classes, 1)))\n",
    "        cpu_Y = cpp.cppTensor(np.zeros((num_classes, 1)))\n",
    "        cpu_dY = cpp.cppTensor(np.zeros((num_classes, 1)))\n",
    "        cpu_loss = cpp.cppTensor(np.zeros((num_classes, 1)))\n",
    "\n",
    "        cpu_model.forward(cpu_outputs, cpu_images, cpu_hprev)\n",
    "        cpu_model.cross_entropy_loss(cpu_dY, cpu_Y, cpu_loss, cpu_outputs, cpu_labels)\n",
    "        cpu_model.backward(cpu_dY)\n",
    "        cpu_model.optimizer()\n",
    "\n",
    "        cpu_iter_loss += np.sum(cpu_loss.numpy())\n",
    "\n",
    "        if (i + 1) % interval == 0:\n",
    "            print(\"cpu epoch {}/{} iter {}/{} loss {:.4f}\".format(epoch + 1, num_epochs, i + 1, total_step, cpu_iter_loss / interval))\n",
    "            print(\"elased time {}\".format(time.time() - start_time))\n",
    "            start_time = time.time()\n",
    "            cpu_iter_loss = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1131ec",
   "metadata": {},
   "source": [
    "# GPU Rnn Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be29bb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train gpu hidden_size 128\n",
      "gpu epoch 1/1 iter 5000/60000 loss 1.2363\n",
      "elased time 29.537625312805176\n",
      "gpu epoch 1/1 iter 10000/60000 loss 0.8144\n",
      "elased time 29.47009825706482\n",
      "gpu epoch 1/1 iter 15000/60000 loss 0.6604\n",
      "elased time 29.434409141540527\n",
      "gpu epoch 1/1 iter 20000/60000 loss 0.5663\n",
      "elased time 29.59179663658142\n",
      "gpu epoch 1/1 iter 25000/60000 loss 0.5250\n",
      "elased time 29.469311475753784\n",
      "gpu epoch 1/1 iter 30000/60000 loss 0.5004\n",
      "elased time 29.455142736434937\n",
      "gpu epoch 1/1 iter 35000/60000 loss 0.4616\n",
      "elased time 29.459095239639282\n",
      "gpu epoch 1/1 iter 40000/60000 loss 0.4368\n",
      "elased time 29.667620182037354\n",
      "gpu epoch 1/1 iter 45000/60000 loss 0.4261\n",
      "elased time 29.827187299728394\n",
      "gpu epoch 1/1 iter 50000/60000 loss 0.4058\n",
      "elased time 29.469065189361572\n",
      "gpu epoch 1/1 iter 55000/60000 loss 0.3760\n",
      "elased time 29.450764417648315\n",
      "gpu epoch 1/1 iter 60000/60000 loss 0.3743\n",
      "elased time 29.455721139907837\n"
     ]
    }
   ],
   "source": [
    "gpu_model = cpp.cppRnn(learning_rate, U, W, V, FC_W, seq_length, input_size, hidden_size, num_classes)\n",
    "gpu_model.cuda()\n",
    "print(\"start train gpu hidden_size {}\".format(hidden_size))\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (train_images, train_labels) in enumerate(train_loader):\n",
    "        train_images = train_images.reshape(seq_length, batch_size, input_size).detach().numpy()\n",
    "        train_labels = train_labels.detach().numpy()\n",
    "        train_hprev = np.zeros((hidden_size, 1))\n",
    "\n",
    "        gpu_images = [cpp.cppTensor(train_images[j]) for j in range(len(train_images))]\n",
    "        gpu_hprev = cpp.cppTensor(train_hprev)\n",
    "        gpu_labels = cpp.cppTensor(train_labels)\n",
    "\n",
    "        gpu_outputs = cpp.cppTensor(np.zeros((num_classes, 1)))\n",
    "        gpu_Y = cpp.cppTensor(np.zeros((num_classes, 1)))\n",
    "        gpu_dY = cpp.cppTensor(np.zeros((num_classes, 1)))\n",
    "        gpu_loss = cpp.cppTensor(np.zeros((num_classes, 1)))\n",
    "\n",
    "        [gpu_images[j].cuda() for j in range(len(gpu_images))]\n",
    "        gpu_hprev.cuda()\n",
    "        gpu_labels.cuda()\n",
    "        \n",
    "        gpu_outputs.cuda()\n",
    "        gpu_Y.cuda()\n",
    "        gpu_dY.cuda()\n",
    "        gpu_loss.cuda()\n",
    "\n",
    "        gpu_model.forward(gpu_outputs, gpu_images, gpu_hprev)\n",
    "        gpu_model.cross_entropy_loss(gpu_dY, gpu_Y, gpu_loss, gpu_outputs, gpu_labels)\n",
    "        gpu_model.backward(gpu_dY)\n",
    "        gpu_model.optimizer()\n",
    "        \n",
    "        gpu_loss.cpu()\n",
    "        gpu_iter_loss += np.sum(gpu_loss.numpy())\n",
    "\n",
    "        if (i + 1) % interval == 0:\n",
    "            print(\"gpu epoch {}/{} iter {}/{} loss {:.4f}\".format(epoch + 1, num_epochs, i + 1, total_step, gpu_iter_loss / interval))\n",
    "            print(\"elased time {}\".format(time.time() - start_time))\n",
    "            start_time = time.time()\n",
    "            gpu_iter_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dffab5",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddd51b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np Accuracy of the model on the 10000 test images: 84.17 %\n",
      "cpu Accuracy of the model on the 10000 test images: 88.21 %\n",
      "gpu Accuracy of the model on the 10000 test images: 88.96 %\n"
     ]
    }
   ],
   "source": [
    "np_correct = 0\n",
    "np_total = 0\n",
    "cpu_correct = 0\n",
    "cpu_total = 0\n",
    "gpu_correct = 0\n",
    "gpu_total = 0\n",
    "\n",
    "def softmax(x):\n",
    "    e = np.exp(x)\n",
    "    return e / np.sum(e)\n",
    "\n",
    "def predict(outputs):\n",
    "    return np.argmax(softmax(outputs), 0)\n",
    "\n",
    "gpu_model.cpu()\n",
    "\n",
    "for test_images, test_labels in test_loader:\n",
    "    np_images = test_images.reshape(seq_length, batch_size, input_size).detach().numpy()\n",
    "    np_hprev = np.zeros((hidden_size, 1))\n",
    "    labels = test_labels.detach().numpy()\n",
    "\n",
    "    cpu_images = [cpp.cppTensor(np_images[j]) for j in range(len(np_images))]\n",
    "    cpu_hprev = cpp.cppTensor(np_hprev)\n",
    "    cpu_outputs = cpp.cppTensor(np.zeros((num_classes, 1)))\n",
    "\n",
    "    gpu_images = [cpp.cppTensor(np_images[j]) for j in range(len(np_images))]\n",
    "    gpu_hprev = cpp.cppTensor(np_hprev)\n",
    "    gpu_outputs = cpp.cppTensor(np.zeros((num_classes, 1)))\n",
    "\n",
    "    np_outputs = np_model.forward(np_images, np_hprev)\n",
    "    np_pred = predict(np_outputs)\n",
    "\n",
    "    np_total += labels.shape[0]\n",
    "    np_correct += (np_pred == labels).sum().item()\n",
    "\n",
    "    cpu_model.forward(cpu_outputs, cpu_images, cpu_hprev)\n",
    "    cpu_pred = predict(cpu_outputs.numpy())\n",
    "\n",
    "    cpu_total += labels.shape[0]\n",
    "    cpu_correct += (cpu_pred == labels).sum().item()\n",
    "    \n",
    "    gpu_model.forward(gpu_outputs, gpu_images, gpu_hprev)\n",
    "    gpu_pred = predict(gpu_outputs.numpy())\n",
    "\n",
    "    gpu_total += labels.shape[0]\n",
    "    gpu_correct += (gpu_pred == labels).sum().item()\n",
    "\n",
    "print('np Accuracy of the model on the 10000 test images: {} %'.format(100 * np_correct / np_total))\n",
    "print('cpu Accuracy of the model on the 10000 test images: {} %'.format(100 * cpu_correct / cpu_total))\n",
    "print('gpu Accuracy of the model on the 10000 test images: {} %'.format(100 * gpu_correct / gpu_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b316048",
   "metadata": {},
   "source": [
    "# Numpy LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "342df0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_LSTM(object):\n",
    "    def __init__(self, x_size, hidden_size, num_classes):\n",
    "        self.lr = learning_rate\n",
    "        self.seq_length = seq_length\n",
    "        self.input_size = x_size + hidden_size\n",
    "        \n",
    "        self.W_f = xavier_init(hidden_size, self.input_size, fc=True)\n",
    "        self.b_f = np.zeros((hidden_size, 1))\n",
    "        \n",
    "        self.W_i = xavier_init(hidden_size, self.input_size, fc=True)\n",
    "        self.b_i = np.zeros((hidden_size, 1))\n",
    "        \n",
    "        self.W_g = xavier_init(hidden_size, self.input_size, fc=True)\n",
    "        self.b_g = np.zeros((hidden_size, 1))\n",
    "        \n",
    "        self.W_o = xavier_init(hidden_size, self.input_size, fc=True)\n",
    "        self.b_o = np.zeros((hidden_size, 1))\n",
    "        \n",
    "        self.W_fc = xavier_init(num_classes, hidden_size, fc=True)\n",
    "        self.b_fc = np.zeros((num_classes, 1))\n",
    "        \n",
    "        self.mW_f = np.zeros_like(self.W_f)\n",
    "        self.mb_f = np.zeros_like(self.b_f)\n",
    "        \n",
    "        self.mW_i = np.zeros_like(self.W_i)\n",
    "        self.mb_i = np.zeros_like(self.b_i)\n",
    "        \n",
    "        self.mW_g = np.zeros_like(self.W_g)\n",
    "        self.mb_g = np.zeros_like(self.b_g)\n",
    "        \n",
    "        self.mW_o = np.zeros_like(self.W_o)\n",
    "        self.mb_o = np.zeros_like(self.b_o)\n",
    "        \n",
    "        self.mW_fc = np.zeros_like(self.W_fc)\n",
    "        self.mb_fc = np.zeros_like(self.b_fc)\n",
    "        \n",
    "        self.X = {}\n",
    "        self.F = {}\n",
    "        self.F_A = {}\n",
    "        \n",
    "        self.I = {}\n",
    "        self.I_A = {}\n",
    "        \n",
    "        self.G = {}\n",
    "        self.G_A = {}\n",
    "        \n",
    "        self.O = {}\n",
    "        self.O_A = {}\n",
    "        \n",
    "        self.C = {}\n",
    "        self.C_A = {}\n",
    "        self.H = {}\n",
    "        \n",
    "    def forward(self, x, hprev, cprev):\n",
    "        self.X = {}\n",
    "        self.F = {}\n",
    "        self.F_A = {}\n",
    "        \n",
    "        self.I = {}\n",
    "        self.I_A = {}\n",
    "        \n",
    "        self.G = {}\n",
    "        self.G_A = {}\n",
    "        \n",
    "        self.O = {}\n",
    "        self.O_A = {}\n",
    "        \n",
    "        self.C = {}\n",
    "        self.C_A = {}\n",
    "        self.H = {}\n",
    "        \n",
    "        self.H[-1] = np.copy(hprev)\n",
    "        self.C[-1] = np.copy(cprev)\n",
    "        \n",
    "        for t in range(self.seq_length):\n",
    "            self.X[t] = np.concatenate((self.H[t-1], x[t].T), axis = 0)\n",
    "            \n",
    "            self.F[t] = self.W_f @ self.X[t] + self.b_f\n",
    "            self.F_A[t] = self.sigmoid(self.F[t])\n",
    "            \n",
    "            self.I[t] = self.W_i @ self.X[t] + self.b_i\n",
    "            self.I_A[t] = self.sigmoid(self.I[t])\n",
    "            \n",
    "            self.G[t] = self.W_g @ self.X[t] + self.b_g\n",
    "            self.G_A[t] = np.tanh(self.G[t])\n",
    "            \n",
    "            self.C[t] = self.F_A[t] * self.C[t - 1] + self.I_A[t] * self.G_A[t]\n",
    "            self.C_A[t] = np.tanh(self.C[t])\n",
    "            \n",
    "            self.O[t] = self.W_o @ self.X[t] + self.b_o\n",
    "            self.O_A[t] = self.sigmoid(self.O[t])\n",
    "            \n",
    "            self.H[t] = self.O_A[t] * self.C_A[t]\n",
    "            \n",
    "        output = self.W_fc @ self.H[self.seq_length - 1] + self.b_fc\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def backward(self, dY):\n",
    "        dW_f, db_f = np.zeros_like(self.W_f), np.zeros_like(self.b_f)\n",
    "        dW_i, db_i = np.zeros_like(self.W_i), np.zeros_like(self.b_i)\n",
    "        dW_g, db_g = np.zeros_like(self.W_g), np.zeros_like(self.b_g)\n",
    "        dW_o, db_o = np.zeros_like(self.W_o), np.zeros_like(self.b_o)\n",
    "        dW_fc, db_fc = np.zeros_like(self.W_fc), np.zeros_like(self.b_fc)\n",
    "        \n",
    "        dH_next = np.zeros_like(self.H[0])\n",
    "        dC_next = np.zeros_like(self.C[0])\n",
    "        \n",
    "        dW_fc = dY @ self.H[self.seq_length - 1].T\n",
    "        db_fc = dY\n",
    "        \n",
    "        for t in reversed(range(self.seq_length)):\n",
    "            dh = self.W_fc.T @ dY + dH_next\n",
    "            \n",
    "            dO_A = dh * self.C_A[t]\n",
    "            dO = dO_A * (self.O_A[t] * (1 - self.O_A[t]))\n",
    "            dW_o += dO @ self.X[t].T\n",
    "            db_o += dO\n",
    "            \n",
    "            dC_A = self.O_A[t] * dh\n",
    "            dC = dC_A * (1 - self.C_A[t] ** 2) + dC_next\n",
    "            \n",
    "            dF_A = dC * self.C[t - 1]\n",
    "            dI_A = dC * self.G_A[t]\n",
    "            dG_A = self.I_A[t] * dC\n",
    "            dC_next = self.F_A[t] * dC\n",
    "            \n",
    "            dF = dF_A * (self.F_A[t] * (1 - self.F_A[t]))\n",
    "            dW_f += dF @ self.X[t].T\n",
    "            db_f += dF\n",
    "            \n",
    "            dI = dI_A * (self.I_A[t] * (1 - self.I_A[t]))\n",
    "            dW_i += dI @ self.X[t].T\n",
    "            db_i += dI\n",
    "            \n",
    "            dG = dG_A * (1 - self.G_A[t] ** 2)\n",
    "            dW_g += dG @ self.X[t].T\n",
    "            db_g += dG\n",
    "            \n",
    "            dX = self.W_f.T @ dF + self.W_i.T @ dI + self.W_g.T @ dG + self.W_o.T @ dO\n",
    "            dH_next = dX[:hidden_size, :]\n",
    "        \n",
    "        gradients = [dW_f, db_f, dW_i, db_i, dW_g, db_g, dW_o, db_o, dW_fc, db_fc]\n",
    "        \n",
    "        return gradients\n",
    "    \n",
    "    def optimizer_step(self, gradients):\n",
    "        for dparam in gradients:\n",
    "            np.clip(dparam, -5, 5, out=dparam)\n",
    "        \n",
    "        for param, dparam, mem in zip(\n",
    "            [self.W_f, self.b_f, self.W_i, self.b_i, self.W_g, self.b_g, self.W_o, self.b_o, self.W_fc, self.b_fc],\n",
    "            gradients,\n",
    "            [self.mW_f, self.mb_f, self.mW_i, self.mb_i, self.mW_g, self.mb_g, self.mW_o, self.mb_o, self.mW_fc, self.mb_fc]):\n",
    "            mem += dparam * dparam\n",
    "            param += -self.lr * dparam / np.sqrt(mem + 1e-8)\n",
    "            \n",
    "    def cross_entropy_loss(self, outputs, labels):\n",
    "        Y = self.softmax(outputs)\n",
    "        loss = -np.log(Y) * self.one_hot_vector(Y, labels)\n",
    "        return Y, loss\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        e = np.exp(x)\n",
    "        return e / np.sum(e)\n",
    "    \n",
    "    def deriv_softmax(self, Y, labels):\n",
    "        dY = np.copy(Y)\n",
    "        for i in range(len(labels)):\n",
    "            dY[labels[i]][i] -= 1\n",
    "        return dY\n",
    "    \n",
    "    def one_hot_vector(self, Y, labels):\n",
    "        out = np.zeros_like(Y)\n",
    "        for i in range(len(labels)):\n",
    "            out[labels[i]][i] = 1\n",
    "        return out\n",
    "    \n",
    "    def predict(self, outputs):\n",
    "        return np.argmax(self.softmax(outputs), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c304429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/2 iter 10000/60000 loss 0.8096\n",
      "epoch 1/2 iter 20000/60000 loss 0.3663\n",
      "epoch 1/2 iter 30000/60000 loss 0.3320\n",
      "epoch 1/2 iter 40000/60000 loss 0.2763\n",
      "epoch 1/2 iter 50000/60000 loss 0.2308\n",
      "epoch 1/2 iter 60000/60000 loss 0.2385\n",
      "epoch 2/2 iter 10000/60000 loss 0.2096\n",
      "epoch 2/2 iter 20000/60000 loss 0.2044\n",
      "epoch 2/2 iter 30000/60000 loss 0.1896\n",
      "epoch 2/2 iter 40000/60000 loss 0.1874\n",
      "epoch 2/2 iter 50000/60000 loss 0.1692\n",
      "epoch 2/2 iter 60000/60000 loss 0.1658\n"
     ]
    }
   ],
   "source": [
    "model = My_LSTM(input_size, hidden_size, num_classes)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "iter_loss = 0\n",
    "interval = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(seq_length, batch_size, input_size).detach().numpy()\n",
    "        labels = labels.detach().numpy()\n",
    "        \n",
    "        hprev = np.zeros((hidden_size, 1))\n",
    "        cprev = np.zeros((hidden_size, 1))\n",
    "        outputs = model.forward(images, hprev, cprev)\n",
    "        Y, loss = model.cross_entropy_loss(outputs, labels)\n",
    "        gradients = model.backward(model.deriv_softmax(Y, labels))\n",
    "        model.optimizer_step(gradients)\n",
    "        iter_loss += np.sum(loss)\n",
    "        if(i + 1) % interval == 0:\n",
    "            print(\"epoch {}/{} iter {}/{} loss {:.4f}\".format(epoch + 1, num_epochs, i + 1, total_step, iter_loss / interval))\n",
    "            iter_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34937150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 94.93 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = images.reshape(seq_length, batch_size, input_size).detach().numpy()\n",
    "    labels = labels.detach().numpy()\n",
    "    \n",
    "    hprev = np.zeros((hidden_size, 1))\n",
    "    cprev = np.zeros((hidden_size, 1))\n",
    "    outputs = model.forward(images, hprev, cprev)\n",
    "    pred = model.predict(outputs)\n",
    "    total += labels.shape[0]\n",
    "    correct += (pred == labels).sum().item()\n",
    "\n",
    "print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total)) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "598a34f14c0623b1f7a078a22e92ee41cc78ba832de8ea969da58fe2ce83dc76"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
